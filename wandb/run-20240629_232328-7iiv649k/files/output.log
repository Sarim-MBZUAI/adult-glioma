/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:406: LightningDeprecationWarning: The NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0. The `Trainer(amp_backend='native')` argument is deprecated. Removing this argument will avoid this message, it will select PyTorch's implementation automatically.
  rank_zero_deprecation(
/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.
  rank_zero_deprecation(
/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python mednext_train.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name      | Type             | Params
-----------------------------------------------
0 | model     | MedNeXt          | 10.5 M
1 | criterion | CriterionWrapper | 0
-----------------------------------------------
10.5 M    Trainable params
0         Non-trainable params
10.5 M    Total params
42.121    Total estimated model params size (MB)

Sanity Checking DataLoader 0:   0%|                                                                          | 0/2 [00:00<?, ?it/s]
/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.


Epoch 0:  78%|███████████████████████████████▉         | 7/9 [00:20<00:05,  2.89s/it, loss=2.25, v_num=649k, train_loss_step=2.200]
Validation: 0it [00:00, ?it/s]



Epoch 1:  78%|▊| 7/9 [00:05<00:01,  1.32it/s, loss=2.22, v_num=649k, train_loss_step=2.170, val_loss=1.150, val_avg=0.00668, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 2:  89%|▉| 8/9 [00:06<00:00,  1.28it/s, loss=2.18, v_num=649k, train_loss_step=2.100, val_loss=1.130, val_avg=0.00731, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.46it/s]





Epoch 3: 100%|█| 9/9 [00:06<00:00,  1.34it/s, loss=2.12, v_num=649k, train_loss_step=2.040, val_loss=1.090, val_avg=0.0316, val_tc=


Epoch 4:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=2.05, v_num=649k, train_loss_step=1.990, val_loss=1.090, val_avg=0.0316, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 5:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=1.99, v_num=649k, train_loss_step=1.970, val_loss=1.060, val_avg=0.026, val_tc=0
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.45it/s]




Epoch 6:  89%|▉| 8/9 [00:06<00:00,  1.25it/s, loss=1.93, v_num=649k, train_loss_step=1.880, val_loss=1.040, val_avg=0.0284, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.46it/s]



Epoch 7:  78%|▊| 7/9 [00:05<00:01,  1.33it/s, loss=1.88, v_num=649k, train_loss_step=1.790, val_loss=1.030, val_avg=0.305, val_tc=0
Validation: 0it [00:00, ?it/s]



Epoch 8:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=1.84, v_num=649k, train_loss_step=1.750, val_loss=1.010, val_avg=0.611, val_tc=0
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 9:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=1.81, v_num=649k, train_loss_step=1.790, val_loss=1.010, val_avg=0.625, val_tc=0
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 10:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=1.78, v_num=649k, train_loss_step=1.620, val_loss=1.000, val_avg=0.759, val_tc=
Validation: 0it [00:00, ?it/s]



Epoch 11:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=1.75, v_num=649k, train_loss_step=1.740, val_loss=0.996, val_avg=0.870, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 12:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=1.72, v_num=649k, train_loss_step=1.610, val_loss=0.989, val_avg=0.878, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 13:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=1.68, v_num=649k, train_loss_step=1.430, val_loss=0.983, val_avg=0.894, val_tc=
Validation: 0it [00:00, ?it/s]




Epoch 14:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=1.63, v_num=649k, train_loss_step=1.530, val_loss=0.977, val_avg=0.875, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 15: 100%|█| 9/9 [00:06<00:00,  1.34it/s, loss=1.58, v_num=649k, train_loss_step=1.480, val_loss=0.961, val_avg=0.517, val_tc=
Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.59it/s]



Epoch 16:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=1.53, v_num=649k, train_loss_step=1.390, val_loss=0.947, val_avg=0.638, val_tc=
Validation: 0it [00:00, ?it/s]




Epoch 17:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=1.49, v_num=649k, train_loss_step=1.400, val_loss=0.929, val_avg=0.643, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 18:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=1.44, v_num=649k, train_loss_step=1.600, val_loss=0.912, val_avg=0.383, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 19:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=1.41, v_num=649k, train_loss_step=1.030, val_loss=0.873, val_avg=0.426, val_tc=
Validation: 0it [00:00, ?it/s]





Epoch 20: 100%|█| 9/9 [00:06<00:00,  1.31it/s, loss=1.38, v_num=649k, train_loss_step=1.340, val_loss=0.868, val_avg=0.271, val_tc=


Epoch 21:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=1.3, v_num=649k, train_loss_step=1.220, val_loss=0.868, val_avg=0.271, val_tc=0
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 22:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=1.3, v_num=649k, train_loss_step=1.490, val_loss=0.876, val_avg=0.507, val_tc=0
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 23:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=1.24, v_num=649k, train_loss_step=1.700, val_loss=0.857, val_avg=0.159, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 24:  89%|▉| 8/9 [00:06<00:00,  1.28it/s, loss=1.21, v_num=649k, train_loss_step=0.532, val_loss=0.922, val_avg=0.581, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 25:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=1.11, v_num=649k, train_loss_step=0.660, val_loss=0.867, val_avg=0.643, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 26:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=1.1, v_num=649k, train_loss_step=0.898, val_loss=0.890, val_avg=0.365, val_tc=0
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 27:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=1.04, v_num=649k, train_loss_step=0.420, val_loss=0.882, val_avg=0.495, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 28:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.959, v_num=649k, train_loss_step=1.680, val_loss=0.891, val_avg=0.859, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 29:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.999, v_num=649k, train_loss_step=1.780, val_loss=0.888, val_avg=0.862, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]




Epoch 30:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.923, v_num=649k, train_loss_step=0.836, val_loss=0.845, val_avg=0.416, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 31:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.942, v_num=649k, train_loss_step=0.755, val_loss=0.846, val_avg=0.411, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 32:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.84, v_num=649k, train_loss_step=0.679, val_loss=0.868, val_avg=0.638, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 33:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.891, v_num=649k, train_loss_step=0.921, val_loss=0.863, val_avg=0.642, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]





Epoch 34: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.862, v_num=649k, train_loss_step=0.973, val_loss=0.832, val_avg=0.302, val_tc


Epoch 35:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.833, v_num=649k, train_loss_step=0.517, val_loss=0.832, val_avg=0.302, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 36:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.875, v_num=649k, train_loss_step=0.819, val_loss=0.846, val_avg=0.660, val_tc
Validation: 0it [00:00, ?it/s]



Epoch 37:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.956, v_num=649k, train_loss_step=0.793, val_loss=0.857, val_avg=0.648, val_tc
Validation: 0it [00:00, ?it/s]



Epoch 38:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.902, v_num=649k, train_loss_step=0.332, val_loss=0.870, val_avg=0.884, val_tc
Validation: 0it [00:00, ?it/s]



Epoch 39:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.91, v_num=649k, train_loss_step=1.550, val_loss=0.849, val_avg=0.534, val_tc=
Validation: 0it [00:00, ?it/s]



Epoch 40:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.894, v_num=649k, train_loss_step=0.352, val_loss=0.864, val_avg=0.641, val_tc
Validation: 0it [00:00, ?it/s]



Epoch 41:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.93, v_num=649k, train_loss_step=0.406, val_loss=0.856, val_avg=0.899, val_tc=

Validation: 0it [00:00, ?it/s]




Epoch 42: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.836, v_num=649k, train_loss_step=0.278, val_loss=0.860, val_avg=0.895, val_tc




Epoch 43: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.781, v_num=649k, train_loss_step=0.757, val_loss=0.840, val_avg=0.292, val_tc




Epoch 44: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.777, v_num=649k, train_loss_step=0.616, val_loss=0.842, val_avg=0.414, val_tc




Epoch 45: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.747, v_num=649k, train_loss_step=0.564, val_loss=0.850, val_avg=0.529, val_tc




Epoch 46: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.811, v_num=649k, train_loss_step=0.357, val_loss=0.847, val_avg=0.289, val_tc




Epoch 47: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.73, v_num=649k, train_loss_step=0.557, val_loss=0.835, val_avg=0.672, val_tc=




Epoch 48: 100%|█| 9/9 [00:06<00:00,  1.34it/s, loss=0.773, v_num=649k, train_loss_step=1.600, val_loss=0.840, val_avg=0.417, val_tc



Epoch 49:  89%|▉| 8/9 [00:06<00:00,  1.28it/s, loss=0.771, v_num=649k, train_loss_step=0.307, val_loss=0.840, val_avg=0.417, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 50:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.803, v_num=649k, train_loss_step=1.510, val_loss=0.839, val_avg=0.295, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 51:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.823, v_num=649k, train_loss_step=0.427, val_loss=0.842, val_avg=0.413, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 52:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.792, v_num=649k, train_loss_step=0.584, val_loss=0.836, val_avg=0.420, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 53:  89%|▉| 8/9 [00:06<00:00,  1.28it/s, loss=0.84, v_num=649k, train_loss_step=0.383, val_loss=0.838, val_avg=0.418, val_tc=
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 54:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.822, v_num=649k, train_loss_step=1.550, val_loss=0.854, val_avg=0.651, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 55:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.875, v_num=649k, train_loss_step=0.613, val_loss=0.848, val_avg=0.659, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 56:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.776, v_num=649k, train_loss_step=0.701, val_loss=0.842, val_avg=0.664, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.58it/s]





Epoch 57: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.791, v_num=649k, train_loss_step=0.249, val_loss=0.830, val_avg=0.426, val_tc




Epoch 58: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.848, v_num=649k, train_loss_step=1.510, val_loss=0.834, val_avg=0.672, val_tc



Epoch 59:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.848, v_num=649k, train_loss_step=0.507, val_loss=0.834, val_avg=0.672, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 60:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.863, v_num=649k, train_loss_step=1.540, val_loss=0.836, val_avg=0.420, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 61:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.763, v_num=649k, train_loss_step=0.568, val_loss=0.859, val_avg=0.893, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 62:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.712, v_num=649k, train_loss_step=0.648, val_loss=0.854, val_avg=0.899, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 63:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.667, v_num=649k, train_loss_step=0.978, val_loss=0.842, val_avg=0.414, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 64:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.766, v_num=649k, train_loss_step=0.521, val_loss=0.845, val_avg=0.411, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 65:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.763, v_num=649k, train_loss_step=1.610, val_loss=0.842, val_avg=0.413, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 66:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.697, v_num=649k, train_loss_step=0.218, val_loss=0.838, val_avg=0.916, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]





Epoch 67: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.76, v_num=649k, train_loss_step=0.308, val_loss=0.833, val_avg=0.547, val_tc=




Epoch 68: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.761, v_num=649k, train_loss_step=0.672, val_loss=0.839, val_avg=0.666, val_tc




Epoch 69: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.74, v_num=649k, train_loss_step=0.541, val_loss=0.838, val_avg=0.667, val_tc=



Epoch 70:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.745, v_num=649k, train_loss_step=1.510, val_loss=0.838, val_avg=0.667, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 71:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.754, v_num=649k, train_loss_step=0.675, val_loss=0.834, val_avg=0.421, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 72:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.823, v_num=649k, train_loss_step=0.474, val_loss=0.837, val_avg=0.917, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 73:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.791, v_num=649k, train_loss_step=0.318, val_loss=0.832, val_avg=0.923, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 74:  89%|▉| 8/9 [00:06<00:00,  1.28it/s, loss=0.786, v_num=649k, train_loss_step=0.563, val_loss=0.835, val_avg=0.919, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 75:  78%|▊| 7/9 [00:05<00:01,  1.33it/s, loss=0.73, v_num=649k, train_loss_step=1.490, val_loss=0.838, val_avg=0.791, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 76:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.726, v_num=649k, train_loss_step=0.671, val_loss=0.831, val_avg=0.424, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 77:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.708, v_num=649k, train_loss_step=1.490, val_loss=0.835, val_avg=0.670, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 78:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.619, v_num=649k, train_loss_step=0.502, val_loss=0.839, val_avg=0.665, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 79:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.727, v_num=649k, train_loss_step=0.380, val_loss=0.848, val_avg=0.655, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 80:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.668, v_num=649k, train_loss_step=0.667, val_loss=0.840, val_avg=0.664, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 81:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.718, v_num=649k, train_loss_step=0.579, val_loss=0.834, val_avg=0.671, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 82:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.617, v_num=649k, train_loss_step=0.327, val_loss=0.833, val_avg=0.672, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 83:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.72, v_num=649k, train_loss_step=0.246, val_loss=0.833, val_avg=0.671, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 84:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.69, v_num=649k, train_loss_step=0.703, val_loss=0.835, val_avg=0.669, val_tc=
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 85:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.7, v_num=649k, train_loss_step=0.207, val_loss=0.838, val_avg=0.541, val_tc=0
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 86:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.691, v_num=649k, train_loss_step=0.623, val_loss=0.839, val_avg=0.414, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 87:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.63, v_num=649k, train_loss_step=0.548, val_loss=0.838, val_avg=0.415, val_tc=

Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]


Epoch 88:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.658, v_num=649k, train_loss_step=0.327, val_loss=0.838, val_avg=0.416, val_tc

Validation: 0it [00:00, ?it/s]


Epoch 89:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.678, v_num=649k, train_loss_step=1.440, val_loss=0.836, val_avg=0.418, val_tc

Validation: 0it [00:00, ?it/s]


Epoch 90:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.683, v_num=649k, train_loss_step=0.659, val_loss=0.836, val_avg=0.418, val_tc

Validation: 0it [00:00, ?it/s]




Epoch 91: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.652, v_num=649k, train_loss_step=1.460, val_loss=0.836, val_avg=0.668, val_tc




Epoch 92: 100%|█| 9/9 [00:06<00:00,  1.34it/s, loss=0.666, v_num=649k, train_loss_step=0.500, val_loss=0.836, val_avg=0.544, val_tc




Epoch 93: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.671, v_num=649k, train_loss_step=0.478, val_loss=0.835, val_avg=0.544, val_tc




Epoch 94: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.589, v_num=649k, train_loss_step=0.613, val_loss=0.836, val_avg=0.669, val_tc




Epoch 95: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.679, v_num=649k, train_loss_step=0.840, val_loss=0.836, val_avg=0.669, val_tc



Epoch 96:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.742, v_num=649k, train_loss_step=1.420, val_loss=0.836, val_avg=0.669, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 97:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.796, v_num=649k, train_loss_step=0.535, val_loss=0.836, val_avg=0.669, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]



Epoch 98:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.763, v_num=649k, train_loss_step=0.471, val_loss=0.836, val_avg=0.669, val_tc
Validation DataLoader 0:   0%|                                                                               | 0/2 [00:00<?, ?it/s]



Epoch 99:  89%|▉| 8/9 [00:06<00:00,  1.32it/s, loss=0.701, v_num=649k, train_loss_step=0.370, val_loss=0.836, val_avg=0.669, val_tc
Validation DataLoader 0:  50%|███████████████████████████████████▌                                   | 1/2 [00:00<00:00,  1.59it/s]

Epoch 99, global step 700: 'val_loss' was not in top 1
`Trainer.fit` stopped: `max_epochs=100` reached.
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Restoring states from the checkpoint path at ./brats2024-goat/7iiv649k/checkpoints/epoch=66-step=469.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./brats2024-goat/7iiv649k/checkpoints/epoch=66-step=469.ckpt
Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.59it/s]
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_avg            0.4276699423789978
         test_et                    1.0
        test_loss           0.8283733129501343
         test_tc                    0.0
         test_wt            0.7106797695159912
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────