/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:406: LightningDeprecationWarning: The NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0. The `Trainer(amp_backend='native')` argument is deprecated. Removing this argument will avoid this message, it will select PyTorch's implementation automatically.
  rank_zero_deprecation(
/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.
  rank_zero_deprecation(
/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python mednext_train.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name      | Type             | Params
-----------------------------------------------
0 | model     | MedNeXt          | 10.5 M
1 | criterion | CriterionWrapper | 0
-----------------------------------------------
10.5 M    Trainable params
0         Non-trainable params
10.5 M    Total params
42.121    Total estimated model params size (MB)

Sanity Checking DataLoader 0:  50%|█████████████████████████████████▌                                 | 1/2 [00:04<00:04,  4.24s/it]
/home/sarim.hashmi/anaconda3/envs/brats_adam/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.



Epoch 0:  89%|█████████████████████████████████████▎    | 8/9 [00:11<00:01,  1.48s/it, loss=2.25, v_num=6nb8, train_loss_step=2.210]
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.22it/s]





Epoch 1: 100%|█| 9/9 [00:06<00:00,  1.35it/s, loss=2.23, v_num=6nb8, train_loss_step=2.170, val_loss=1.120, val_avg=0.0346, val_tc=0


Epoch 2:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=2.19, v_num=6nb8, train_loss_step=2.090, val_loss=1.120, val_avg=0.0346, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]





Epoch 3: 100%|█| 9/9 [00:06<00:00,  1.36it/s, loss=2.12, v_num=6nb8, train_loss_step=2.040, val_loss=1.080, val_avg=0.0468, val_tc=0


Epoch 4:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=2.05, v_num=6nb8, train_loss_step=1.990, val_loss=1.080, val_avg=0.0468, val_tc=0
Validation: 0it [00:00, ?it/s]




Epoch 5:  89%|▉| 8/9 [00:06<00:00,  1.33it/s, loss=2, v_num=6nb8, train_loss_step=1.920, val_loss=1.050, val_avg=0.0181, val_tc=0.00
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]





Epoch 6: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=1.94, v_num=6nb8, train_loss_step=1.880, val_loss=1.010, val_avg=0.016, val_tc=0.


Epoch 7:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=1.9, v_num=6nb8, train_loss_step=1.870, val_loss=1.010, val_avg=0.016, val_tc=0.0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]




Epoch 8:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=1.86, v_num=6nb8, train_loss_step=1.760, val_loss=1.000, val_avg=0.187, val_tc=0.
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.61it/s]





Epoch 9: 100%|█| 9/9 [00:06<00:00,  1.31it/s, loss=1.83, v_num=6nb8, train_loss_step=1.800, val_loss=0.984, val_avg=0.267, val_tc=0.


Epoch 10:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=1.79, v_num=6nb8, train_loss_step=1.730, val_loss=0.984, val_avg=0.267, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]





Epoch 11: 100%|█| 9/9 [00:06<00:00,  1.37it/s, loss=1.75, v_num=6nb8, train_loss_step=1.730, val_loss=0.964, val_avg=0.279, val_tc=0


Epoch 12:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=1.72, v_num=6nb8, train_loss_step=1.800, val_loss=0.964, val_avg=0.279, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]




Epoch 13:  89%|▉| 8/9 [00:05<00:00,  1.34it/s, loss=1.7, v_num=6nb8, train_loss_step=1.770, val_loss=0.952, val_avg=0.276, val_tc=0.
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 14:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=1.67, v_num=6nb8, train_loss_step=1.530, val_loss=0.943, val_avg=0.276, val_tc=0

Validation: 0it [00:00, ?it/s]



Epoch 15:  89%|▉| 8/9 [00:05<00:00,  1.35it/s, loss=1.63, v_num=6nb8, train_loss_step=1.310, val_loss=0.929, val_avg=0.277, val_tc=0
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.61it/s]





Epoch 16: 100%|█| 9/9 [00:06<00:00,  1.35it/s, loss=1.59, v_num=6nb8, train_loss_step=1.170, val_loss=0.895, val_avg=0.297, val_tc=0


Epoch 17:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=1.52, v_num=6nb8, train_loss_step=1.350, val_loss=0.895, val_avg=0.297, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]





Epoch 18: 100%|█| 9/9 [00:06<00:00,  1.37it/s, loss=1.46, v_num=6nb8, train_loss_step=1.640, val_loss=0.863, val_avg=0.307, val_tc=0


Epoch 19:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=1.42, v_num=6nb8, train_loss_step=1.740, val_loss=0.863, val_avg=0.307, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]




Epoch 20:  89%|▉| 8/9 [00:06<00:00,  1.33it/s, loss=1.39, v_num=6nb8, train_loss_step=1.290, val_loss=0.860, val_avg=0.323, val_tc=0
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 21:  89%|▉| 8/9 [00:06<00:00,  1.32it/s, loss=1.3, v_num=6nb8, train_loss_step=1.250, val_loss=0.864, val_avg=0.192, val_tc=0.
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]





Epoch 22: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=1.26, v_num=6nb8, train_loss_step=1.440, val_loss=0.844, val_avg=0.299, val_tc=0


Epoch 23:  78%|▊| 7/9 [00:05<00:01,  1.39it/s, loss=1.21, v_num=6nb8, train_loss_step=1.590, val_loss=0.844, val_avg=0.299, val_tc=0

Validation: 0it [00:00, ?it/s]


Epoch 24:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=1.18, v_num=6nb8, train_loss_step=0.496, val_loss=0.819, val_avg=0.286, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]




Epoch 25:  89%|▉| 8/9 [00:06<00:00,  1.33it/s, loss=1.08, v_num=6nb8, train_loss_step=0.451, val_loss=0.813, val_avg=0.261, val_tc=0
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 26:  89%|▉| 8/9 [00:05<00:00,  1.35it/s, loss=1.02, v_num=6nb8, train_loss_step=0.810, val_loss=0.774, val_avg=0.314, val_tc=0
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]




Epoch 27:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=1.03, v_num=6nb8, train_loss_step=0.429, val_loss=0.757, val_avg=0.324, val_tc=0
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]





Epoch 28: 100%|█| 9/9 [00:06<00:00,  1.34it/s, loss=1.03, v_num=6nb8, train_loss_step=1.540, val_loss=0.719, val_avg=0.340, val_tc=0


Epoch 29:  78%|▊| 7/9 [00:05<00:01,  1.32it/s, loss=0.976, v_num=6nb8, train_loss_step=1.720, val_loss=0.719, val_avg=0.340, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 30:  78%|▊| 7/9 [00:05<00:01,  1.33it/s, loss=0.97, v_num=6nb8, train_loss_step=0.435, val_loss=0.723, val_avg=0.316, val_tc=0

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 31:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.966, v_num=6nb8, train_loss_step=0.541, val_loss=0.717, val_avg=0.332, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]




Epoch 32:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.899, v_num=6nb8, train_loss_step=0.744, val_loss=0.692, val_avg=0.366, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 33:  89%|▉| 8/9 [00:06<00:00,  1.31it/s, loss=0.921, v_num=6nb8, train_loss_step=1.120, val_loss=0.760, val_avg=0.273, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.61it/s]





Epoch 34:  89%|▉| 8/9 [00:08<00:01,  1.09s/it, loss=0.921, v_num=6nb8, train_loss_step=0.748, val_loss=0.676, val_avg=0.377, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.61it/s]



Epoch 35:  78%|▊| 7/9 [00:05<00:01,  1.21it/s, loss=0.899, v_num=6nb8, train_loss_step=1.680, val_loss=0.688, val_avg=0.354, val_tc=

Validation: 0it [00:00, ?it/s]




Epoch 36: 100%|█| 9/9 [00:06<00:00,  1.31it/s, loss=0.869, v_num=6nb8, train_loss_step=0.485, val_loss=0.686, val_avg=0.348, val_tc=




Epoch 37: 100%|█| 9/9 [00:06<00:00,  1.31it/s, loss=0.953, v_num=6nb8, train_loss_step=0.402, val_loss=0.663, val_avg=0.382, val_tc=


Epoch 38:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.843, v_num=6nb8, train_loss_step=0.259, val_loss=0.663, val_avg=0.382, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 39:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.907, v_num=6nb8, train_loss_step=1.510, val_loss=0.668, val_avg=0.381, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 40:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.923, v_num=6nb8, train_loss_step=0.366, val_loss=0.683, val_avg=0.350, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 41:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.998, v_num=6nb8, train_loss_step=1.530, val_loss=0.679, val_avg=0.359, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 42:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.86, v_num=6nb8, train_loss_step=0.315, val_loss=0.664, val_avg=0.383, val_tc=0

Validation: 0it [00:00, ?it/s]


Epoch 43:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.843, v_num=6nb8, train_loss_step=0.399, val_loss=0.727, val_avg=0.299, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 44:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.782, v_num=6nb8, train_loss_step=0.641, val_loss=0.681, val_avg=0.353, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 45:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.798, v_num=6nb8, train_loss_step=0.768, val_loss=0.676, val_avg=0.368, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 46:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.876, v_num=6nb8, train_loss_step=1.670, val_loss=0.738, val_avg=0.286, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 47:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.876, v_num=6nb8, train_loss_step=0.612, val_loss=0.659, val_avg=0.393, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 48:  78%|▊| 7/9 [00:05<00:01,  1.33it/s, loss=0.855, v_num=6nb8, train_loss_step=1.540, val_loss=0.662, val_avg=0.370, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 49:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.755, v_num=6nb8, train_loss_step=0.327, val_loss=0.665, val_avg=0.362, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 50:  89%|▉| 8/9 [00:06<00:00,  1.32it/s, loss=0.827, v_num=6nb8, train_loss_step=1.580, val_loss=0.651, val_avg=0.388, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 51:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.859, v_num=6nb8, train_loss_step=0.642, val_loss=0.682, val_avg=0.350, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 52:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.782, v_num=6nb8, train_loss_step=0.610, val_loss=0.675, val_avg=0.360, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 53:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.829, v_num=6nb8, train_loss_step=0.579, val_loss=0.665, val_avg=0.374, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 54:  89%|▉| 8/9 [00:06<00:00,  1.29it/s, loss=0.867, v_num=6nb8, train_loss_step=1.440, val_loss=0.658, val_avg=0.382, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.61it/s]



Epoch 55:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.938, v_num=6nb8, train_loss_step=0.457, val_loss=0.671, val_avg=0.360, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 56:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.86, v_num=6nb8, train_loss_step=0.404, val_loss=0.681, val_avg=0.346, val_tc=0
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 57:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.768, v_num=6nb8, train_loss_step=0.231, val_loss=0.670, val_avg=0.365, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 58:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.819, v_num=6nb8, train_loss_step=1.510, val_loss=0.664, val_avg=0.373, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 59:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.851, v_num=6nb8, train_loss_step=0.567, val_loss=0.669, val_avg=0.368, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 60:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.862, v_num=6nb8, train_loss_step=1.400, val_loss=0.677, val_avg=0.357, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 61:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.787, v_num=6nb8, train_loss_step=0.688, val_loss=0.655, val_avg=0.387, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 62:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.699, v_num=6nb8, train_loss_step=0.655, val_loss=0.659, val_avg=0.380, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 63:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.682, v_num=6nb8, train_loss_step=0.622, val_loss=0.682, val_avg=0.347, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 64:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.791, v_num=6nb8, train_loss_step=0.479, val_loss=0.651, val_avg=0.392, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 65:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.788, v_num=6nb8, train_loss_step=1.440, val_loss=0.666, val_avg=0.369, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 66:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.755, v_num=6nb8, train_loss_step=0.204, val_loss=0.699, val_avg=0.328, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 67:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.804, v_num=6nb8, train_loss_step=0.252, val_loss=0.654, val_avg=0.385, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 68:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.801, v_num=6nb8, train_loss_step=0.600, val_loss=0.653, val_avg=0.385, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 69:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.766, v_num=6nb8, train_loss_step=0.592, val_loss=0.670, val_avg=0.360, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 70:  78%|▊| 7/9 [00:05<00:01,  1.34it/s, loss=0.801, v_num=6nb8, train_loss_step=1.430, val_loss=0.667, val_avg=0.364, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 71:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.817, v_num=6nb8, train_loss_step=0.354, val_loss=0.651, val_avg=0.388, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 72:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.845, v_num=6nb8, train_loss_step=0.581, val_loss=0.654, val_avg=0.385, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 73:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.814, v_num=6nb8, train_loss_step=1.480, val_loss=0.652, val_avg=0.385, val_tc=

Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]


Epoch 74:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.816, v_num=6nb8, train_loss_step=0.578, val_loss=0.661, val_avg=0.370, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 75:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.817, v_num=6nb8, train_loss_step=1.470, val_loss=0.661, val_avg=0.369, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 76:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.796, v_num=6nb8, train_loss_step=0.340, val_loss=0.655, val_avg=0.377, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 77:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.787, v_num=6nb8, train_loss_step=1.410, val_loss=0.667, val_avg=0.363, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 78:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.694, v_num=6nb8, train_loss_step=0.482, val_loss=0.672, val_avg=0.358, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 79:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.748, v_num=6nb8, train_loss_step=0.552, val_loss=0.666, val_avg=0.365, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 80:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.75, v_num=6nb8, train_loss_step=0.331, val_loss=0.658, val_avg=0.377, val_tc=0

Validation: 0it [00:00, ?it/s]


Epoch 81:  78%|▊| 7/9 [00:05<00:01,  1.38it/s, loss=0.8, v_num=6nb8, train_loss_step=0.344, val_loss=0.656, val_avg=0.380, val_tc=0.

Validation: 0it [00:00, ?it/s]


Epoch 82:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.767, v_num=6nb8, train_loss_step=1.450, val_loss=0.656, val_avg=0.380, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 83:  78%|▊| 7/9 [00:05<00:01,  1.37it/s, loss=0.764, v_num=6nb8, train_loss_step=0.243, val_loss=0.660, val_avg=0.374, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 84:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.793, v_num=6nb8, train_loss_step=0.709, val_loss=0.666, val_avg=0.366, val_tc=

Validation: 0it [00:00, ?it/s]


Epoch 85:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.79, v_num=6nb8, train_loss_step=0.207, val_loss=0.666, val_avg=0.366, val_tc=0

Validation: 0it [00:00, ?it/s]


Epoch 86:  78%|▊| 7/9 [00:05<00:01,  1.35it/s, loss=0.803, v_num=6nb8, train_loss_step=0.325, val_loss=0.667, val_avg=0.366, val_tc=

Validation: 0it [00:00, ?it/s]




Epoch 87: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.694, v_num=6nb8, train_loss_step=0.599, val_loss=0.662, val_avg=0.371, val_tc=




Epoch 88: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.639, v_num=6nb8, train_loss_step=0.413, val_loss=0.661, val_avg=0.374, val_tc=




Epoch 89: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.681, v_num=6nb8, train_loss_step=1.490, val_loss=0.661, val_avg=0.374, val_tc=




Epoch 90: 100%|█| 9/9 [00:06<00:00,  1.32it/s, loss=0.721, v_num=6nb8, train_loss_step=0.363, val_loss=0.664, val_avg=0.369, val_tc=




Epoch 91: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.779, v_num=6nb8, train_loss_step=1.450, val_loss=0.664, val_avg=0.370, val_tc=




Epoch 92: 100%|█| 9/9 [00:06<00:00,  1.35it/s, loss=0.797, v_num=6nb8, train_loss_step=0.535, val_loss=0.663, val_avg=0.371, val_tc=




Epoch 93: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.749, v_num=6nb8, train_loss_step=0.531, val_loss=0.662, val_avg=0.371, val_tc=




Epoch 94: 100%|█| 9/9 [00:06<00:00,  1.33it/s, loss=0.671, v_num=6nb8, train_loss_step=0.345, val_loss=0.662, val_avg=0.371, val_tc=



Epoch 95:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.684, v_num=6nb8, train_loss_step=0.463, val_loss=0.662, val_avg=0.371, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 96:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.756, v_num=6nb8, train_loss_step=1.520, val_loss=0.662, val_avg=0.371, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.62it/s]



Epoch 97:  89%|▉| 8/9 [00:06<00:00,  1.30it/s, loss=0.873, v_num=6nb8, train_loss_step=0.370, val_loss=0.661, val_avg=0.372, val_tc=
Validation DataLoader 0:  50%|████████████████████████████████████                                    | 1/2 [00:00<00:00,  1.63it/s]



Epoch 98:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.796, v_num=6nb8, train_loss_step=0.448, val_loss=0.661, val_avg=0.373, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]



Epoch 99:  78%|▊| 7/9 [00:05<00:01,  1.36it/s, loss=0.739, v_num=6nb8, train_loss_step=0.323, val_loss=0.660, val_avg=0.374, val_tc=
Validation DataLoader 0:   0%|                                                                                | 0/2 [00:00<?, ?it/s]

Epoch 99, global step 700: 'val_loss' was not in top 1
`Trainer.fit` stopped: `max_epochs=100` reached.
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Restoring states from the checkpoint path at ./brats2024-goat/8whn6nb8/checkpoints/epoch=49-step=350.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./brats2024-goat/8whn6nb8/checkpoints/epoch=49-step=350.ckpt
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.62it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_avg            0.3876359760761261
         test_et             0.265593558549881
        test_loss           0.6510292738676071
         test_tc            0.3052791655063629
         test_wt            0.6738057136535645
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────